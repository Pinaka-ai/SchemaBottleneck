{"tokenizer": {"model_name": "t5-base", "padding_side": "left", "truncation_side": "left", "pad_token_as_eos_token": false}, "reward_fn": {"id": "mse"}, "datapool": {"id": "morality", "args": {"prompt_prefix": "Generate aspects for evaluating morality: "}}, "env": {"n_envs": 10, "args": {"max_prompt_length": 512, "max_episode_length": 100, "terminate_on_eos": true, "prompt_truncation_side": "right", "context_start_token": 0}}, "alg": {"id": "ppo", "args": {"n_steps": 512, "batch_size": 2, "verbose": 1, "learning_rate": 2e-06, "n_epochs": 5, "ent_coef": 0.0}, "kl_div": {"coeff": 0.01, "target_kl": 0.2}, "policy": {"id": "seq2seq_lm_actor_critic_policy", "args": {"model_name": "tmp_sup/rl4lm_exps/rl4lm_experiment/model", "apply_model_parallel": true, "prompt_truncation_side": "right", "generation_kwargs": {"do_sample": true, "top_k": 100, "min_length": 50, "max_new_tokens": 100}}}}, "train_evaluation": {"eval_batch_size": 2, "n_iters": 50, "eval_every": 10, "save_every": 1, "metrics": [{"id": "mse"}], "generation_kwargs": {"do_sample": true, "top_k": 0, "temperature": 0.7, "min_length": 50, "max_new_tokens": 100}}}